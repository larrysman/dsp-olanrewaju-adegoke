{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8a5b77",
   "metadata": {},
   "source": [
    "## House Price Modeling Using Linear Regression\n",
    "\n",
    "**Data Science in Production**\n",
    "\n",
    "###### data source: https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data?select=train.csv\n",
    "\n",
    "**`Adegoke Olanrewaju`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f20d22",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c8622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad205f",
   "metadata": {},
   "source": [
    "### Model Building Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318d0ed",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5edc3a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPATH = '/Users/OLALYTICS/dsp-olanrewaju-adegoke/data/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f96729e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LinearRegression(), {'rmsle': 0.27})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(dataPATH: str) -> dict[str, str]:\n",
    "\n",
    "    # Loading the train.csv dataset from path\n",
    "    dataset = load_selected_dataset(dataPATH)\n",
    "\n",
    "    # Selecting the categorical and continuous columns of interest\n",
    "    categorical_features, continuous_features = select_features_columns()\n",
    "\n",
    "    # Defining the features and target\n",
    "    features, target = features_target_selection(dataset, categorical_features, continuous_features)\n",
    "\n",
    "    # Splitting of the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Preprocessing and feature engineering of the X_train set\n",
    "    X_train, X_test = preprocessing(categorical_features, continuous_features, X_train, X_test)\n",
    "\n",
    "    # Automatic checking of the DataFrame Equality for X_train dataset\n",
    "    X_train, X_test = DataFrame_Equality(dataPATH, X_train, X_test)\n",
    "\n",
    "    # Model training and fitting\n",
    "    LinReg = training_model(X_train, y_train)\n",
    "\n",
    "    # Model predictions of the X_test\n",
    "    y_predicted = model_prediction(X_test)\n",
    "\n",
    "    # Model evaluation and model performance\n",
    "    rmsle = model_performance(y_test, y_predicted)\n",
    "\n",
    "    return LinReg, rmsle\n",
    "\n",
    "\n",
    "\n",
    "def DataFrame_Equality(dataPATH, X_train, X_test):\n",
    "    X_train = x_train_dataframe_equality_check(dataPATH, X_train)\n",
    "    X_test = x_test_dataframe_equality_check(dataPATH, X_test)\n",
    "    return X_train,X_test\n",
    "\n",
    "def x_test_dataframe_equality_check(dataPATH, X_test):\n",
    "    X_test_df = save_load_to_parquet_x_test(dataPATH, X_test)\n",
    "    X_test, X_test_df = resetting_index_parquet_x_test(X_test, X_test_df)       \n",
    "    pd.testing.assert_frame_equal(X_test_df, X_test)\n",
    "    return X_test\n",
    "\n",
    "def x_train_dataframe_equality_check(dataPATH, X_train):\n",
    "    X_train_df = save_load_to_parquet_x_train(dataPATH, X_train)\n",
    "    X_train, X_train_df = resetting_index_parquet_x_train(X_train, X_train_df)     \n",
    "    pd.testing.assert_frame_equal(X_train_df, X_train)\n",
    "    return X_train\n",
    "\n",
    "def features_target_selection(dataset, categorical_features, continuous_features):\n",
    "    features = dataset[categorical_features + continuous_features]\n",
    "    target = dataset['SalePrice']\n",
    "    return features,target\n",
    "\n",
    "def select_features_columns():\n",
    "    categorical_features = ['MSZoning','HouseStyle']\n",
    "    continuous_features = ['YearBuilt','TotalBsmtSF','MiscVal']\n",
    "    return categorical_features,continuous_features\n",
    "\n",
    "def model_performance(y_test: np.ndarray, y_predicted: np.ndarray) -> dict[str,str]:\n",
    "    msle = mean_squared_log_error(y_test, y_predicted)\n",
    "    rmsle = round(np.sqrt(msle), 2)\n",
    "    model_rmsle = {'rmsle' : rmsle}\n",
    "    return model_rmsle\n",
    "\n",
    "def load_selected_dataset(dataPATH):\n",
    "    train_csv_master = pd.read_csv(dataPATH)\n",
    "    train_csv = train_csv_master.copy()\n",
    "    dataset = train_csv[['MSZoning','HouseStyle','YearBuilt','TotalBsmtSF','MiscVal','SalePrice']]\n",
    "    return dataset\n",
    "\n",
    "def model_prediction(X_test):\n",
    "    LinReg_model = joblib.load('../models/LinReg.joblib')\n",
    "    y_predicted = LinReg_model.predict(X_test)\n",
    "    return y_predicted\n",
    "\n",
    "def preprocessing(categorical_features, continuous_features, X_train, X_test):\n",
    "    X_train = preprocessing_x_train(categorical_features, continuous_features, X_train)\n",
    "    X_test = preprocessing_x_test(categorical_features, continuous_features, X_test)\n",
    "    return X_train,X_test\n",
    "\n",
    "def resetting_index_parquet_x_test(X_test, X_test_df):\n",
    "    X_test_df = X_test_df.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    return X_test,X_test_df\n",
    "\n",
    "def save_load_to_parquet_x_test(dataPATH, X_test):\n",
    "    X_test.to_parquet(dataPATH + 'X_test_df.parquet', index=False)\n",
    "    X_test_df = pd.read_parquet(dataPATH + 'X_test_df.parquet')\n",
    "    return X_test_df\n",
    "\n",
    "def preprocessing_x_test(categorical_features, continuous_features, X_test):\n",
    "    X_test_cat_DF = encoding_categorical_features(categorical_features, X_test)\n",
    "    X_test_cont_DF = scaling_continuous_features(continuous_features, X_test)\n",
    "    X_test = pd.concat([X_test_cont_DF, X_test_cat_DF], axis=1)\n",
    "    return X_test\n",
    "\n",
    "def scaling_continuous_features(continuous_features, X_test):\n",
    "    loaded_stdScaler = joblib.load('../models/stdScaler.joblib')\n",
    "    X_test_cont = loaded_stdScaler.transform(X_test[continuous_features])\n",
    "    X_test_cont_DF = pd.DataFrame(X_test_cont, columns=continuous_features)\n",
    "    return X_test_cont_DF\n",
    "\n",
    "def encoding_categorical_features(categorical_features, X_test):\n",
    "    loaded_oneHot = joblib.load('../models/oneHot.joblib')\n",
    "    X_test_cat = loaded_oneHot.transform(X_test[categorical_features])\n",
    "    X_test_cat_DF = pd.DataFrame(X_test_cat, columns = loaded_oneHot.get_feature_names(categorical_features ))\n",
    "    return X_test_cat_DF\n",
    "\n",
    "def training_model(X_train, y_train):\n",
    "    LinReg = LinearRegression()\n",
    "    LinReg.fit(X_train, y_train)\n",
    "    LinReg = LinearRegression()\n",
    "    LinReg.fit(X_train, y_train)\n",
    "    joblib.dump(LinReg, '../models/LinReg.joblib')\n",
    "    return LinReg\n",
    "\n",
    "def resetting_index_parquet_x_train(X_train, X_train_df):\n",
    "    X_train_df = X_train_df.reset_index(drop=True)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    return X_train,X_train_df\n",
    "\n",
    "def save_load_to_parquet_x_train(dataPATH, X_train):\n",
    "    X_train.to_parquet(dataPATH + 'X_train_df.parquet', index=False)\n",
    "    X_train_df = pd.read_parquet(dataPATH + 'X_train_df.parquet')\n",
    "    return X_train_df\n",
    "\n",
    "def preprocessing_x_train(categorical_features, continuous_features, X_train):\n",
    "    X_train_cat_DF = encoding_categorical_features(categorical_features, X_train)\n",
    "    X_train_cont_DF = scaling_continuous_features(continuous_features, X_train)\n",
    "    X_train = pd.concat([X_train_cont_DF, X_train_cat_DF], axis=1)\n",
    "    return X_train\n",
    "\n",
    "def scaling_continuous_features(continuous_features, X_train):\n",
    "    stdScaler = StandardScaler()\n",
    "    stdScaler.fit(X_train[continuous_features])\n",
    "    X_train_cont = stdScaler.transform(X_train[continuous_features])\n",
    "    X_train_cont_DF = pd.DataFrame(X_train_cont, columns=continuous_features)\n",
    "    joblib.dump(stdScaler, '../models/stdScaler.joblib')\n",
    "    return X_train_cont_DF\n",
    "\n",
    "def encoding_categorical_features(categorical_features, X_train):\n",
    "    oneHot = OneHotEncoder(drop = 'first', sparse=False)\n",
    "    oneHot.fit(X_train[categorical_features])\n",
    "    X_train_cat = oneHot.transform(X_train[categorical_features])\n",
    "    X_train_cat_DF = pd.DataFrame(X_train_cat, columns=oneHot.get_feature_names(categorical_features ))\n",
    "    joblib.dump(oneHot, '../models/oneHot.joblib')\n",
    "    return X_train_cat_DF\n",
    "\n",
    "#returning the root_mean_log_squared_error\n",
    "build_model(dataPATH)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae65de",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef0587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPATH = '/Users/OLALYTICS/dsp-olanrewaju-adegoke/data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3ad941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c6/ht4lr6411jqdn8bhdr_m1dh00000gp/T/ipykernel_92099/57443601.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_csv_features.dropna(inplace=True)\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n",
      "/Users/OLALYTICS/anaconda3/envs/ml/lib/python3.9/site-packages/sklearn/utils/validation.py:571: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  array.dtypes.apply(is_sparse).any()):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([110610.50906774, 175679.06302268, 225803.59054318, 226381.68473571,\n",
       "       199957.53776718])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_predictions(input_data: pd.DataFrame) -> np.ndarray:\n",
    "    # Loading and reading the given test.csv dataset\n",
    "    test_csv = load_test_data()\n",
    "\n",
    "    # Defining the categorical and continuous features of the test_csv\n",
    "    categorical_features, continuous_features = selecting_features_columns_test_data()\n",
    "\n",
    "    # Selecting the categorical and continuous features of the test_csv\n",
    "    test_csv_features = test_csv[categorical_features + continuous_features]\n",
    "\n",
    "    # Preprocessing of the test_csv\n",
    "    test_set = preprocessing_test_data(categorical_features, continuous_features, test_csv_features)\n",
    "\n",
    "    # Automatic checking of DataFrame Equality for the test_csv data\n",
    "    dataframe_equality_check_test_data(test_set)\n",
    "\n",
    "    # Predicting the house prices using the test_csv dataset\n",
    "    predictions = make_prediction(test_set)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "def make_prediction(test_set):\n",
    "    LinReg_model = joblib.load('../models/LinReg.joblib')\n",
    "    predictions = LinReg_model.predict(test_set)\n",
    "    return predictions[:5]\n",
    "\n",
    "def dataframe_equality_check_test_data(test_set):\n",
    "    final_test_csv, final_test_csv_df = save_and_load_parquet_test_csv(test_set)\n",
    "    final_test_csv, final_test_csv_df = resetting_index_of_dataframe(final_test_csv, final_test_csv_df)       \n",
    "    pd.testing.assert_frame_equal(final_test_csv_df, final_test_csv)\n",
    "\n",
    "def selecting_features_columns_test_data():\n",
    "    categorical_features = ['MSZoning','HouseStyle']\n",
    "    continuous_features = ['YearBuilt','TotalBsmtSF','MiscVal']\n",
    "    return categorical_features,continuous_features\n",
    "\n",
    "def load_test_data():\n",
    "    test_csv_master = pd.read_csv(dataPATH)\n",
    "    test_csv = test_csv_master.copy()\n",
    "    return test_csv\n",
    "\n",
    "def resetting_index_of_dataframe(final_test_csv, final_test_csv_df):\n",
    "    final_test_csv_df = final_test_csv_df.reset_index(drop=True)\n",
    "    final_test_csv = final_test_csv.reset_index(drop=True)\n",
    "    return final_test_csv,final_test_csv_df\n",
    "\n",
    "def save_and_load_parquet_test_csv(test_set):\n",
    "    final_test_csv = test_set\n",
    "    final_test_csv.to_parquet(dataPATH + 'final_test_csv_df.parquet', index=False)\n",
    "    final_test_csv_df = pd.read_parquet(dataPATH + 'final_test_csv_df.parquet')\n",
    "    return final_test_csv,final_test_csv_df\n",
    "\n",
    "def preprocessing_test_data(categorical_features, continuous_features, test_csv_features):\n",
    "    check_and_correct_NaN(test_csv_features)\n",
    "    test_csv_cat_DF = encoding_categorical_features_test_data(categorical_features, test_csv_features)\n",
    "    test_csv_cont_DF = scaling_continuous_features_test_data(continuous_features, test_csv_features)\n",
    "    test_set = pd.concat([test_csv_cont_DF, test_csv_cat_DF],axis=1)\n",
    "    return test_set\n",
    "\n",
    "def scaling_continuous_features_test_data(continuous_features, test_csv_features):\n",
    "    loaded_stdScaler = joblib.load('../models/stdScaler.joblib')\n",
    "    test_csv_cont = loaded_stdScaler.transform(test_csv_features[continuous_features])\n",
    "    test_csv_cont_DF = pd.DataFrame(test_csv_cont, columns=continuous_features)\n",
    "    return test_csv_cont_DF\n",
    "\n",
    "def encoding_categorical_features_test_data(categorical_features, test_csv_features):\n",
    "    loaded_oneHot = joblib.load('../models/oneHot.joblib')\n",
    "    test_csv_cat = loaded_oneHot.transform(test_csv_features[categorical_features])\n",
    "    test_csv_cat_DF = pd.DataFrame(test_csv_cat, columns=loaded_oneHot.get_feature_names(categorical_features ))\n",
    "    return test_csv_cat_DF\n",
    "\n",
    "def check_and_correct_NaN(test_csv_features):\n",
    "    test_csv_features.isna().sum()\n",
    "    test_csv_features.dropna(inplace=True)\n",
    "    \n",
    "# Making the Predictions for the test_csv dataset returning an array\n",
    "make_predictions(dataPATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
